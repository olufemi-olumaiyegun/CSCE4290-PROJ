{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "787b3cf41a9906e633ae1a27e26fe5e99a4ea5aaa48667274724f83566a4406b"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('fpl': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsnz2ga93R0j",
        "outputId": "12c570cb-edd1-4199-b3c6-fdbba7eded11"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEugiscQc0R5",
        "outputId": "1f96f889-c7bb-48c2-de56-2f3f597bc64b"
      },
      "source": [
        "!pip install gensim\n",
        "!pip install wget\n",
        "  \n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBK1ok8fk3CK"
      },
      "source": [
        "import zipfile\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUCJJ03H6Qfu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0LtHAPpmcHV"
      },
      "source": [
        "import wget\n",
        "glove_dir = \"glove\"\n",
        "glove_url = \"https://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip\"\n",
        "\n",
        "if not os.path.exists(glove_dir):\n",
        "    os.mkdir(glove_dir)\n",
        "\n",
        "# Download glove vector\n",
        "wget.download(glove_url, out=glove_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK47tN7Dk3JN"
      },
      "source": [
        "\n",
        "\n",
        "# Extract glove file\n",
        "with zipfile.ZipFile(os.path.join(\"glove\", \"glove.42B.300d.zip\"), \"r\") as z:\n",
        "    z.extractall(glove_dir)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdfEnN3UB8je"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0lkSVX7TqFg"
      },
      "source": [
        "replacements = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hb9Flgc83hl"
      },
      "source": [
        "from datasets import load_dataset\n",
        " \n",
        "dss_train = load_dataset('wikihow','all',data_dir='/content/drive/MyDrive',split='train')\n",
        "dss_test = load_dataset('wikihow','all',data_dir='/content/drive/MyDrive',split='test')\n",
        "dss_valid = load_dataset('wikihow','all',data_dir='/content/drive/MyDrive',split='validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6oMHyo116Re"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-T4tOYWHPK"
      },
      "source": [
        "import pandas\n",
        "ds_train = pandas.DataFrame(data=dss_train)[:10000]\n",
        "ds_test = pandas.DataFrame(data=dss_test)[:5000]\n",
        "ds_valid = pandas.DataFrame(data=dss_valid)[:5000]\n",
        "\n",
        "ds_train.drop_duplicates(subset=['text'],inplace=True)  #dropping duplicates\n",
        "ds_train.dropna(axis=0,inplace=True)   #dropping na\n",
        "ds_valid.drop_duplicates(subset=['text'],inplace=True)  #dropping duplicates\n",
        "ds_valid.dropna(axis=0,inplace=True)   #dropping na\n",
        "\n",
        "ds_train.drop_duplicates(subset=['headline'],inplace=True)  #dropping duplicates\n",
        "ds_train.dropna(axis=0,inplace=True)   #dropping na\n",
        "ds_valid.drop_duplicates(subset=['headline'],inplace=True)  #dropping duplicates\n",
        "ds_valid.dropna(axis=0,inplace=True)   #dropping na"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHRWU2vDZRai"
      },
      "source": [
        "dss_train_headline = list(ds_train['headline'])\n",
        "dss_train_text = list(ds_train['text'])\n",
        "dss_test_headline = list(ds_test['headline'])\n",
        "dss_test_text = list(ds_test['text'])\n",
        "dss_valid_headline = list(ds_valid['headline'])\n",
        "dss_valid_text = list(ds_valid['text'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neIiNPTQUMlf"
      },
      "source": [
        "from nltk.corpus import  stopwords\n",
        "import re\n",
        "stop_words = set(stopwords.words('english')) \n",
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([replacements[t] if t in replacements else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>=3:                  #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()\n",
        "cleaned_text_train = []\n",
        "cleaned_text_val = []\n",
        "\n",
        "for t in dss_train_text:\n",
        "    cleaned_text_train.append(text_cleaner(t))\n",
        "for d in dss_valid_text:\n",
        "    cleaned_text_val.append(text_cleaner(d))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVXFRr7sFAp3"
      },
      "source": [
        "import numpy as np\n",
        "def summary_cleaner(text):\n",
        "    newString = re.sub('\"','', text)\n",
        "    newString = ' '.join([replacements[t] if t in replacements else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newString = newString.lower()\n",
        "    tokens=newString.split()\n",
        "    newString=''\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                 \n",
        "            newString=newString+i+' '  \n",
        "    return newString\n",
        "#Call the above function\n",
        "cleaned_summary_train = []\n",
        "\n",
        "cleaned_summary_val = []\n",
        "for t in dss_train_headline:\n",
        "    cleaned_summary_train.append(summary_cleaner(t))\n",
        "for t in dss_valid_headline:\n",
        "    cleaned_summary_val.append(summary_cleaner(t))\n",
        "ds_train['text']=cleaned_text_train\n",
        "ds_train['headline']=cleaned_summary_train\n",
        "ds_train['headline'].replace('', np.nan, inplace=True)\n",
        "ds_train.dropna(axis=0,inplace=True)\n",
        "\n",
        "ds_valid['text']=cleaned_text_val\n",
        "ds_valid['headline']=cleaned_summary_val\n",
        "ds_valid['headline'].replace('', np.nan, inplace=True)\n",
        "ds_valid.dropna(axis=0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyQWWvcNYjYf"
      },
      "source": [
        "ds_train['headline'] = ds_train['headline'].apply(lambda x : \" seosartt \" + x + \"  teosarss \")\n",
        "ds_valid['headline'] = ds_valid['headline'].apply(lambda x : \" seosartt \"+ x + \" teosarss \")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "yzBU7cskZJeY",
        "outputId": "2f042a71-1c23-4deb-a31a-70a32629a313"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "# populate the lists with sentence lengths\n",
        "for i in ds_train['text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "for i in ds_train['headline']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "length_df = pandas.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "print(length_df.mean())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text       302.464132\n",
            "summary     52.110555\n",
            "dtype: float64\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufdv3kGThNQT"
      },
      "source": [
        "from tensorflow import keras \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUQaa1V0Yfu8"
      },
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "def generate_dict(data_arr,content_max_len,*args, **kwargs):\n",
        "    #prepare a tokenizer for reviews on training data\n",
        "    _tokenizer = Tokenizer()\n",
        "\n",
        "    if len(args) > 0:\n",
        "        cnt = args[0]\n",
        "        print(cnt)\n",
        "        if cnt:\n",
        "            _tokenizer = Tokenizer(num_words=cnt)\n",
        "            print(\"found\")\n",
        "\n",
        "    _tokenizer.fit_on_texts(list(data_arr))\n",
        "    #convert text sequences into integer sequences\n",
        "    data_arr    =   _tokenizer.texts_to_sequences(data_arr) \n",
        "    #padding zero upto maximum length\n",
        "    data_arr    =   pad_sequences(data_arr,  maxlen=content_max_len, padding='post') \n",
        "    vocabulary_size   =  len(_tokenizer.word_index) +1\n",
        "    return (data_arr,vocabulary_size,_tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukMLaFVdWGIH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30KCkVNOO7x2",
        "outputId": "1729d690-54fb-430f-dccc-f205da0855ee"
      },
      "source": [
        "\n",
        "thresh=50\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in train_tokenizer_text.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 85.04577822990844\n",
            "Total Coverage of rare words: 8.675018499045194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK0kKDj7QmYl"
      },
      "source": [
        "d_cnt = tot_cnt-cnt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dELiQboHcMO-",
        "outputId": "c61dd3ea-5e55-4117-a96f-49fb26d98869"
      },
      "source": [
        "seq_train_text,vocab_size_train_text, train_tokenizer_text = generate_dict(ds_train['text'],303, d_cnt)\n",
        "seq_train_summary,vocab_size_summary, train_tokenizer_summary = generate_dict(ds_train['headline'],53)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6321\n",
            "found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcX6MjuWeY_m",
        "outputId": "643c5cc2-7ff7-4e01-9024-ac8aa9209e66"
      },
      "source": [
        "seq_valid_text,vocab_size_val_text, val_tokenizer_text = generate_dict(ds_valid['text'],303, d_cnt)\n",
        "seq_valid_summary,vocab_size_val_summary, val_tokenizer_summary = generate_dict(ds_valid['headline'],53, d_cnt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6321\n",
            "found\n",
            "6321\n",
            "found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRqfc7u66z8U"
      },
      "source": [
        "\n",
        "ind=[]\n",
        "for i in range(len(seq_train_summary)):\n",
        "    cnt=0\n",
        "    for j in seq_train_summary[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "seq_train_summary=np.delete(seq_train_summary,ind, axis=0)\n",
        "seq_train_text=np.delete(seq_train_text,ind, axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvsF4EHQUsNb",
        "outputId": "da3c3c13-1483-4ebe-a37b-cb07e2f46926"
      },
      "source": [
        "seq_train_text.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9995, 303)"
            ]
          },
          "execution_count": 309,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTdZVgqgSSHK"
      },
      "source": [
        "\n",
        "ind=[]\n",
        "for i in range(len(seq_valid_summary)):\n",
        "    cnt=0\n",
        "    for j in seq_valid_summary[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "seq_valid_summary=np.delete(seq_valid_summary,ind, axis=0)\n",
        "seq_valid_text=np.delete(seq_valid_text,ind, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7gyB1q0c0R6"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import collections\n",
        "import pickle\n",
        "import numpy as np\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from gensim.test.utils import get_tmpfile\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "\n",
        "def build_dict(step, toy=False):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    if step == \"train\":\n",
        "\n",
        "        words = list()\n",
        "        for sent in ds_train['text'][:5000] + ds_train['headline'][:5000]:\n",
        "            for word in sent.split():\n",
        "                words.append(word)\n",
        "\n",
        "        word_counter = collections.Counter(words).most_common()\n",
        "        word_dict = dict()\n",
        "       \n",
        "        for word, _ in word_counter:\n",
        "            word_dict[word] = len(word_dict)\n",
        "        word_dict['mepadding'] = 0\n",
        "        with open(\"word_dict.pickle\", \"wb\") as f:\n",
        "            pickle.dump(word_dict, f)\n",
        "\n",
        "    elif step == \"valid\":\n",
        "        with open(\"word_dict.pickle\", \"rb\") as f:\n",
        "            word_dict = pickle.load(f)\n",
        "\n",
        "    reversed_dict = dict(zip(word_dict.values(), word_dict.keys()))\n",
        "\n",
        "    article_max_len = 303\n",
        "    summary_max_len = 53\n",
        "\n",
        "    return word_dict, reversed_dict, article_max_len, summary_max_len\n",
        "\n",
        "\n",
        "\n",
        "def batch_iter(inputs, outputs, batch_size, num_epochs):\n",
        "    inputs = np.array(inputs)\n",
        "    outputs = np.array(outputs)\n",
        "\n",
        "    num_batches_per_epoch = (len(inputs) - 1) // batch_size + 1\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_num in range(num_batches_per_epoch):\n",
        "            start_index = batch_num * batch_size\n",
        "            end_index = min((batch_num + 1) * batch_size, len(inputs))\n",
        "            yield inputs[start_index:end_index], outputs[start_index:end_index]\n",
        "\n",
        "def get_init_embedding(reversed_dict, embedding_size):\n",
        "    glove_file = \"glove/glove.42B.300d.txt\"\n",
        "    word2vec_file = get_tmpfile(\"word2vec_format.vec\")\n",
        "    glove2word2vec(glove_file, word2vec_file)\n",
        "    print(\"Loading Glove vectors...\")\n",
        "    word_vectors = KeyedVectors.load_word2vec_format(word2vec_file)\n",
        "\n",
        "    word_vec_list = list()\n",
        "    for _, word in sorted(reversed_dict.items()):\n",
        "        try:\n",
        "            word_vec = word_vectors.word_vec(word)\n",
        "        except KeyError:\n",
        "            word_vec = np.zeros([embedding_size], dtype=np.float32)\n",
        "\n",
        "        word_vec_list.append(word_vec)\n",
        "    return np.array(word_vec_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ2EvCaZc0R7",
        "outputId": "e22c70ad-ddf0-45b0-f9f5-d848b3fe3cf9"
      },
      "source": [
        "!pip install tensorflow==1.15.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.7/dist-packages (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.37.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.41.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.13.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.8.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emp0WV-lc0R8",
        "outputId": "207d554e-f937-476c-afd6-56aeba58d860"
      },
      "source": [
        "import time\n",
        "start = time.perf_counter()\n",
        "import argparse\n",
        "import os\n",
        "#from model import Model\n",
        "#from utils import build_dict, build_dataset, batch_iter\n",
        "\n",
        "# Uncomment next 2 lines to suppress error and Tensorflow info verbosity. Or change logging levels\n",
        "# tf.logging.set_verbosity(tf.logging.FATAL)\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "#def add_arguments(parser):\n",
        "#    parser.add_argument(\"--num_hidden\", type=int, default=150, help=\"Network size.\")\n",
        "#    parser.add_argument(\"--num_layers\", type=int, default=2, help=\"Network depth.\")\n",
        "#    parser.add_argument(\"--beam_width\", type=int, default=10, help=\"Beam width for beam search decoder.\")\n",
        "#    parser.add_argument(\"--glove\", action=\"store_true\", help=\"Use glove as initial word embedding.\")\n",
        "#    parser.add_argument(\"--embedding_size\", type=int, default=300, help=\"Word embedding size.\")\n",
        "#\n",
        "#    parser.add_argument(\"--learning_rate\", type=float, default=1e-3, help=\"Learning rate.\")\n",
        "#    parser.add_argument(\"--batch_size\", type=int, default=64, help=\"Batch size.\")\n",
        "#    parser.add_argument(\"--num_epochs\", type=int, default=10, help=\"Number of epochs.\")\n",
        "#    parser.add_argument(\"--keep_prob\", type=float, default=0.8, help=\"Dropout keep prob.\")\n",
        "#\n",
        "#    parser.add_argument(\"--toy\", action=\"store_true\", help=\"Use only 50K samples of data\")\n",
        "#\n",
        "#    parser.add_argument(\"--with_model\", action=\"store_true\", help=\"Continue from previously saved model\")\n",
        "\n",
        "class args:\n",
        "    pass\n",
        "  \n",
        "args.num_hidden=150\n",
        "args.num_layers=2\n",
        "args.beam_width=10\n",
        "args.glove=\"store_true\"\n",
        "args.embedding_size=300\n",
        "\n",
        "args.learning_rate=1e-3\n",
        "args.batch_size=64\n",
        "args.num_epochs=10\n",
        "args.keep_prob = 0.8\n",
        "\n",
        "args.toy=False #\"store_true\"\n",
        "\n",
        "args.with_model=\"store_true\"\n",
        "\n",
        "\n",
        "#parser = argparse.ArgumentParser()\n",
        "#add_arguments(parser)\n",
        "#args = parser.parse_args()\n",
        "#with open(\"args.pickle\", \"wb\") as f:\n",
        "#    pickle.dump(args, f)\n",
        "\n",
        "if not os.path.exists(\"saved_model\"):\n",
        "    os.mkdir(\"saved_model\")\n",
        "\n",
        "\n",
        "print(\"Building dictionary...\")\n",
        "word_dict, reversed_dict, article_max_len, summary_max_len = build_dict(\"train\", args.toy)\n",
        "print(\"Loading training dataset...\")\n",
        "train_x, train_y = seq_train_text, seq_train_summary\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building dictionary...\n",
            "Loading training dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK9TkXJO96AM"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xmuA7tJ_ooV"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.layers import Layer\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzsP_j969eA_",
        "outputId": "536366af-6bf5-4aa6-d321-990bd44a9fee"
      },
      "source": [
        "\n",
        "from tensorflow.keras import backend as K \n",
        "K.clear_session() \n",
        "latent_dim = 500 \n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(article_max_len,)) \n",
        "enc_emb = Embedding(vocab_size_text, latent_dim,trainable=True)(encoder_inputs) \n",
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "#LSTM 3 \n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(vocab_size_summary, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(vocab_size_summary, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 303)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 303, 500)     21135000    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 303, 500),   2002000     ['embedding[0][0]']              \n",
            "                                 (None, 500),                                                     \n",
            "                                 (None, 500)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 303, 500),   2002000     ['lstm[0][0]']                   \n",
            "                                 (None, 500),                                                     \n",
            "                                 (None, 500)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 500)    8440000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 303, 500),   2002000     ['lstm_1[0][0]']                 \n",
            "                                 (None, 500),                                                     \n",
            "                                 (None, 500)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 500),  2002000     ['embedding_1[0][0]',            \n",
            "                                 (None, 500),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 500)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, None, 500),  500500     ['lstm_2[0][0]',                 \n",
            " r)                              (None, None, 303))               'lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 1000)   0           ['lstm_3[0][0]',                 \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 16880)  16896880   ['concat_layer[0][0]']           \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 54,980,380\n",
            "Trainable params: 54,980,380\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX_ucM3Q_zq_"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2MbfFA-Cthd",
        "outputId": "d88ae416-9793-4087-caf3-b7fd863f6e49"
      },
      "source": [
        "history=model.fit([seq_train_text,seq_train_summary[:,:-1]], seq_train_summary.reshape(seq_train_summary.shape[0],seq_train_summary.shape[1], 1)[:,1:] ,epochs=10,callbacks=[es],batch_size=64, validation_data=([seq_val_text,seq_val_summary[:,:-1]], seq_val_summary.reshape(seq_val_summary.shape[0],seq_val_summary.shape[1], 1)[:,1:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 411s 3s/step - loss: 4.8811 - val_loss: 4.7204\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 400s 3s/step - loss: 4.2621 - val_loss: 4.3301\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 400s 3s/step - loss: 3.9723 - val_loss: 4.2125\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 400s 3s/step - loss: 3.7664 - val_loss: 4.1628\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 400s 3s/step - loss: 3.5953 - val_loss: 4.1100\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 401s 3s/step - loss: 3.4455 - val_loss: 4.0752\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 400s 3s/step - loss: 3.3026 - val_loss: 4.0598\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 401s 3s/step - loss: 3.1675 - val_loss: 4.0502\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 400s 3s/step - loss: 3.0310 - val_loss: 4.0522\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 400s 3s/step - loss: 2.9019 - val_loss: 4.0564\n",
            "Epoch 00010: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "psoR0ZhGUmT5",
        "outputId": "03a47dc3-c977-4e48-eb58-f8f1ee4bba30"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Glmc2TudUq5d"
      },
      "source": [
        "reverse_target_word_index=train_tokenizer_summary.index_word\n",
        "reverse_source_word_index=train_tokenizer_text.index_word\n",
        "target_word_index=train_tokenizer_summary.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tbWQ9lDXUvF3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nO1iCo-5UyrZ"
      },
      "source": [
        "\n",
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(article_max_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BE7ODdn5Uzoq"
      },
      "source": [
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = word_dict['seosartt']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reversed_dict[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='teosarss'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'teosarss'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QQRLmj0Cv1Y9",
        "outputId": "09a813cc-6129-4288-aaf4-1b882fb9a2e2"
      },
      "source": [
        "ds_train['headline'][:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     seosartt keep related supplies in the same ar...\n",
              "1     seosartt create sketch in the neopoprealist m...\n",
              "Name: headline, dtype: object"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jQPxClFMU2tY"
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=word_dict['seosartt']) and i!=word_dict['teosarss'] and i!=word_dict['mepadding']):\n",
        "            newString=newString+reversed_dict[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reversed_dict[i]+' '\n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "faQ5Q7akU5lu",
        "outputId": "c441d46d-89ad-4709-ac8d-dc422f3c489b"
      },
      "source": [
        "for i in range(10):\n",
        "    print(\"Reference:\",dss_valid_headline[i])\n",
        "\n",
        "    print(\"Original summary:\",seq2summary(seq_val_summary[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(seq_val_text[i].reshape(1,article_max_len)))\n",
        "    print(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reference: Drink more water.\n",
            "Eat breakfast.\n",
            "Eat well throughout the day.\n",
            "Eat at the right times.\n",
            "Consider going meatless.\n",
            "Read the labels.\n",
            "Get in shape.\n",
            "Maintain a healthy weight.\n",
            "Cross train.\n",
            "Exercise wisely.\n",
            "Take the little opportunities.\n",
            "Think positively.\n",
            "Be satisfied.\n",
            "Think small.\n",
            "Manage stress.\n",
            "Choose your friends wisely.\n",
            "Be productive.\n",
            "Take a break.\n",
            "Find emotional balance.\n",
            "Stop engaging in risky behavior.\n",
            "Exercise several times a week.\n",
            "Get a good night's rest.\n",
            "Learn how to cook.\n",
            "Maintain your personal hygiene.\n",
            "Bolster your immune system.\n",
            "Original summary: treatment ignore result remember leash water make phone jealous cats exams one competition cats increase studies date for the with leash one soaked water sex things lay thought eye features cat plumage up remember second ways stick day many mean whole away food your commercial pick the dry boyfriend the tails angry like \n",
            "Predicted summary:  make tend help long get person your one around cat make slightly ask make part cat lower get sleep about your one around cat make slightly ask make add amount cat make part get know your one many boyfriend ask the lower cat make part ask the part would like mepadding mepadding\n",
            "\n",
            "\n",
            "Reference: Sit next to your crush.\n",
            "Initiate conversations with your crush.\n",
            "Start conversations with school-related topics.\n",
            "Be kind to your crush.\n",
            "Greet them.\n",
            "Connect on social media.\n",
            "Flirt.\n",
            "Understand that your crush is human.\n",
            "Original summary: time number either your the pressure syringe calories want the pressure best calories want sibling habits excessive one kind your the pressure locate of disorder need do coop uncomfortable going take the pressure keep personality like \n",
            "Predicted summary:  the pressure use get know the pressure with also never also never sides your the pressure use get sleep might looks cat make lead want the pressure use get sleep might looks cat make lead want the pressure use get sleep might looks cat the it to never to with like mepadding\n",
            "\n",
            "\n",
            "Reference: Build a trustworthy bond with your piggy.\n",
            "Research different training methods.\n",
            "Choose the training method that works best for you and your guinea pig.\n",
            "Gather the materials that you will need for training.\n",
            "Original summary: time medical positioned rice want the jerk lot experience cold balanced for make cold says take wearing sleeping try get also the women without early make maintain take get place treat try cold like \n",
            "Predicted summary:  make women without use get know make without your day even want make women without get place one need make else help make women without place one need make else help make another small make women without need make else help make women without your make women without looking help make women\n",
            "\n",
            "\n",
            "Reference: Master the basics.\n",
            "Be creative.\n",
            "Stay safe.\n",
            "Take it beyond your home.\n",
            "Original summary: time actual make observe one appointment instead size water feel kid the understand like \n",
            "Predicted summary:  make women without use get know make without keep about your way make without keep make room tend help make women without your make another also make women without keep make room people also make without place one oil your make easy use get know might noise type your day make without\n",
            "\n",
            "\n",
            "Reference: Brainstorm.\n",
            "Focus on the energy over the specific message.\n",
            "Think about the past, present, and future.\n",
            "State your intent first.\n",
            "Original summary: time relaxed toys need make event hand make vegetables wide cats make toy disease also they per the journey example like \n",
            "Predicted summary:  the focus one around your the care to never to care get well one around want the start also the start try the foods it sure the foods care to get sleep might your cage the exercise your the with also the with also never sides your the start also the with\n",
            "\n",
            "\n",
            "Reference: Send cues of interest.\n",
            "Be confident.\n",
            "Approach him with his group of friends.\n",
            "Create an opportunity.\n",
            "Introduce yourself.\n",
            "Make small talk.\n",
            "Get acquainted with his interests.\n",
            "Give him a compliment.\n",
            "Volunteer personal things about yourself.\n",
            "Flirt with him.\n",
            "Suggest that you two hang out.\n",
            "Original summary: time online urge help alarm one necessary maybe let want together several help with in hamster intercourse mom around sure increase say day devotion want together full think let information member dry blood around uncomfortable want let perform take get come front like \n",
            "Predicted summary:  the foods full one around one kind your the comfort one kind your the with also never one kind your the with also never sides also never sides your the comfort to never sides see the care your note the with want with also never also with want the with also never\n",
            "\n",
            "\n",
            "Reference: Start with small talk and be friendly.\n",
            "Ask thoughtful questions.\n",
            "Share information about yourself.\n",
            "Be a good listener.\n",
            "Tell a joke to lighten the mood.\n",
            "Original summary: time best want increase say also one onto see stops daily level school around one many states pain pups your spreads make suggest like \n",
            "Predicted summary:  the pressure one girls want the with also never also with see the with your say your the with also never see the with your the with also never see the with your the with also never see the with your the with also never sides see the care your clean get\n",
            "\n",
            "\n",
            "Reference: Avoid putting him on a pedestal.\n",
            "Remind yourself of past failed relationships.\n",
            "Be yourself if you want it to last.\n",
            "Original summary: time back unable let need platelets party around help toy shirt one around use get person feel your case like \n",
            "Predicted summary:  make lead get know your one with want the start also never sides also never sides also never sides also never also never sides also never sides also never sides also never sides also never sides also never sides also never sides also never also never sides also never also never sides\n",
            "\n",
            "\n",
            "Reference: Sharpen up your social skills in the months prior.\n",
            "Dress appropriately.Looking good is an important part of meeting and attracting women no matter where you are.\n",
            "Stay busy.\n",
            "Act friendly.Above all, it doesn't hurt your chances to be sincerely friendly towards people while you're out on vacation.\n",
            "Carry something to share with others.If you carry something as simple as a pack of smokes or playing cards, you'll have a physical proper conversations with.\n",
            "Original summary: days get sleep instead tray create onto seek every feel already might office the waste your one lately onto towards eat set get sleep need trees collar relationship your level want guy use get collar relationship you milk you decision help to quiet peer get place know changes due calories want like \n",
            "Predicted summary:  the it use get know make helps people get well know your one around want the with also never sides also never sides also never sides also never sides also never sides also never sides also never sides also never sides also never sides also never cat the it also never also\n",
            "\n",
            "\n",
            "Reference: Keep the conversation light-hearted.Even if you're looking to make a serious romance with the girl you're talking with, you shouldn't touch upon any serious topics when you're first chatting with her.\n",
            "Invite her to do something with you.You shouldn't wait long into a conversation before asking the girl to do something fun with you.\n",
            "Take advantage of a vacation's excitement.Unlike a romance closer to home, there's a much greater degree of excitement when you're out on vacation.\n",
            "Share good experiences together.A vacation is meant to be a time where you get out and do things you're not familiar with.\n",
            "Look for signs of attraction.As with any interaction with a woman you're interested in, you can gauge the likelihood of your success by looking at signs of attraction.\n",
            "Act quickly.Vacations don't last long, so your window of opportunity will almost always be accordingly brief.\n",
            "Practice safety first.Vacationers who meet other singles are more likely to practice unsafe sexual practices than if they were back at home.\n",
            "Original summary: concern make electrolytes help the stimulant pig proper body hold help aerobic create putting immunizations way might case buy litter the grass help intercourse place dolphin next one weak physician two late example attention note could decline sleep right perfect your two license patterns dietary plan use consider dogs however body understand like \n",
            "Predicted summary:  the lead also the tree use consider sleep might fruits see the start try clean use get know noise fruits fruits cat make push see the start use consider sleep might fruits see the start use consider sleep might fruits see the start try important with also never sides like mepadding mepadding\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gQIM8BmtjXf"
      },
      "source": [
        "!pip install sumeval\n",
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGYJmZvmtoao"
      },
      "source": [
        "from sumeval.metrics.rouge import RougeCalculator\n",
        "\n",
        "def eval_rouges(refrence_summary,model_summary):\n",
        "    #refrence_summary = \"tokyo shares close up #.## percent\"\n",
        "    #model_summary = \"tokyo stocks close up # percent to fresh record high\"\n",
        "\n",
        "    rouge = RougeCalculator(stopwords=True, lang=\"en\")\n",
        "\n",
        "    rouge_1 = rouge.rouge_n(\n",
        "                summary=model_summary,\n",
        "                references=refrence_summary,\n",
        "                n=1)\n",
        "\n",
        "    rouge_2 = rouge.rouge_n(\n",
        "                summary=model_summary,\n",
        "                references=[refrence_summary],\n",
        "                n=2)\n",
        "    \n",
        "    rouge_l = rouge.rouge_l(\n",
        "                summary=model_summary,\n",
        "                references=[refrence_summary])\n",
        "    \n",
        "    # You need spaCy to calculate ROUGE-BE\n",
        "    \n",
        "    rouge_be = rouge.rouge_be(\n",
        "                summary=model_summary,\n",
        "                references=[refrence_summary])\n",
        "\n",
        "  \n",
        "    \n",
        "    return rouge_1, rouge_2,rouge_l,rouge_be\n",
        "  \n",
        "#rouge_1, rouge_2,rouge_l,rouge_be = eval_rouges( \"tokyo shares close up #.## percent\",\n",
        "#                                                \"tokyo stocks close up # percent to fresh record high\")\n",
        "#\n",
        "#print(\"ROUGE-1: {}, ROUGE-2: {}, ROUGE-L: {}, ROUGE-BE: {}\".format(\n",
        "#        rouge_1, rouge_2, rouge_l, rouge_be\n",
        "#    ).replace(\", \", \"\\n\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-838UhmuuA-f"
      },
      "source": [
        "#https://pymotw.com/2/xml/etree/ElementTree/create.html\n",
        "\n",
        "rouge_1_arr  = []\n",
        "rouge_2_arr  = []\n",
        "rouge_L_arr  = []\n",
        "rouge_be_arr = []\n",
        "\n",
        "from xml.etree import ElementTree\n",
        "from xml.dom import minidom\n",
        "from functools import reduce\n",
        "\n",
        "def prettify(elem):\n",
        "    \"\"\"Return a pretty-printed XML string for the Element.\n",
        "    \"\"\"\n",
        "    rough_string = ElementTree.tostring(elem, 'utf-8')\n",
        "    reparsed = minidom.parseString(rough_string)\n",
        "    return reparsed.toprettyxml(indent=\"  \")\n",
        "  \n",
        "from xml.etree.ElementTree import Element, SubElement, Comment\n",
        "\n",
        "top = Element('CSCE4290')\n",
        "\n",
        "comment = Comment('Generated by Olufemi')\n",
        "top.append(comment)\n",
        "article =  ds_valid['text']\n",
        "reference = ds_valid['headline']\n",
        "i=0\n",
        "for summ in summary_array:\n",
        "  example = SubElement(top, 'example')\n",
        "  article_element   = SubElement(example, 'article')\n",
        "  article_element.text =article[i]\n",
        "  \n",
        "  reference_element = SubElement(example, 'reference')\n",
        "  reference_element.text = reference[i]\n",
        "  \n",
        "  summary_element   = SubElement(example, 'summary')\n",
        "  summary_element.text = summ\n",
        "\n",
        "  rouge_1, rouge_2,rouge_L,rouge_be = eval_rouges(reference[i],summ )\n",
        "\n",
        "  eval_element = SubElement(example, 'eval')\n",
        "  ROUGE_1_element  = SubElement(eval_element, 'ROUGE_1' , {'score':str(rouge_1)})\n",
        "  ROUGE_2_element  = SubElement(eval_element, 'ROUGE_2' , {'score':str(rouge_2)})\n",
        "  ROUGE_L_element  = SubElement(eval_element, 'ROUGE_l' , {'score':str(rouge_L)})\n",
        "  ROUGE_be_element  = SubElement(eval_element,'ROUGE_be', {'score':str(rouge_be)})\n",
        "  \n",
        "  rouge_1_arr.append(rouge_1) \n",
        "  rouge_2_arr.append(rouge_2) \n",
        "  rouge_L_arr.append(rouge_L) \n",
        "  rouge_be_arr.append(rouge_be) \n",
        "\n",
        "  i+=1\n",
        "\n",
        "top.set('rouge_1', str(reduce(lambda x, y: x + y,  rouge_1_arr) / len(rouge_1_arr)))\n",
        "top.set('rouge_2', str(reduce(lambda x, y: x + y,  rouge_2_arr) / len(rouge_2_arr)))\n",
        "top.set('rouge_L', str(reduce(lambda x, y: x + y,  rouge_L_arr) / len(rouge_L_arr)))\n",
        "top.set('rouge_be', str(reduce(lambda x, y: x + y, rouge_be_arr) / len(rouge_be_arr)))\n",
        "\n",
        "with open(\"results.xml\", \"w+\") as f:\n",
        "  print(prettify(top), file=f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "clGVzbPh0961",
        "outputId": "871415ac-a0f4-4546-daa3-a83d87e36c76"
      },
      "source": [
        "summary_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}